{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "Here we explain the fundamental mechanism of discrete backpropagation on the following introductory machine learning model: the binarized perceptron or nonlinear regression. Before we begin, we must explain some fundamental concepts:\n",
    "\n",
    "**Definition 1** - A matrix is said to be binarized if it only takes entries in $\\{-1,+1\\}$.\n",
    "\n",
    "**Definition 2** - The Hamming Distance denoted $d$ of two binarized matrices $A$ and $B$ of equal size is given by: $$d(A,B)=\\dfrac12\\sum_{i} A_i + B_i$$\n",
    "\n",
    "or in plain english \"*the number of entries that are different between the two matrices*\".\n",
    "\n",
    "**Definition 3** - We typically denote a sample-wise ground truth $z$ and an input $x$ and batched ground truth $Z$ and an input $X$.\n",
    "\n",
    "**Definition 4** - Given a binarized ground truth $Z$ and an input $X$, a binarized perceptron aims to find a binarized matrix $W$ and an integer vector $b$ to compute $\\hat{Z}$ via:\n",
    "\n",
    "$$\\hat{Z} = \\text{sign}(XW - b)$$\n",
    "\n",
    "Where $\\text{sign}$ is given by:\n",
    "\n",
    "$$\\text{sign}(x)=\\begin{cases}-1\\qquad \\text{if }x<0\\\\ +1\\qquad \\text{if }x\\geq 0 \\end{cases}$$\n",
    "\n",
    "Such that, $d(Z,\\hat{Z})$ is minimized by correct choice of $W$ and $b$.\n",
    "\n",
    "**Note 1** the matrix multiplication is taken to be ordinary matrix multiplication as one would do on integer matrices, if we map $-1\\to 0$ and $+1\\to 1$ in typical binary fashion - we replace the multiplication in the individual dot products with an bitwise XNOR and addition is then taken to be a population count/*Hamming weight* of the bit-string left after this XNOR'ing.\n",
    "\n",
    "**Note 2** In practice, transistor-for-transistor *XOR* gates are simpler to implement and indeed in the experimental binary warp-level matrix multiply and accumulate instructions available on post-Turing Nvidia GPUs this is what actually gets used - and similarly in FPGA - however, the underlying mathematics of perceptron changes little and we can still train successfully in this regime.\n",
    "\n",
    "This has problem has already been solved in various ways using either PlumerAi's Latent-Free approach or Bengio-et-al's Latent approach. In this notebook, I identify and explain a new approach which builds on PlumerAi's Latent-Free approach that I call \"discrete optimization\".\n",
    "\n",
    "### Discrete Optimization\n",
    "\n",
    "Discrete Optimization works on the following simple observation: that in the dot product of two binarized vectors, that the individual entries of both vectors can only work to either increment or decrement the final dot product.\n",
    "\n",
    "This obvious fact, can be applied to find an optimization signal for the Perceptron. To simplify matters we'll first consider the case of a single sample $x$ and a single ground truth label $z$, for both we'll assume size 10. $\\hat{z}$ is produced by the Perceptron formula and we can compare this against $z$.\n",
    "\n",
    "```\n",
    "z_hat = -1 +1 -1 -1 +1 -1 -1 -1 -1 -1 -1 -1\n",
    "z     = -1 +1 -1 -1 -1 +1 -1 -1 -1 -1 -1 -1 \n",
    "```\n",
    "\n",
    "Here we have a few different kinds of behaviors which encode various signals:\n",
    "\n",
    "1. Predicted: -1/+1, Truth: -1/+1 respectively, correct prediction - nothing to optimize here\n",
    "2. Predicted: -1, Truth: +1, false negative - dot product between input $x$ and corresponding column in $W$ minus bias term $b$ was too **small**!\n",
    "3. Predicted: +1, Truth: -1, false positive - dot product between input $x$ and corresponding column in $W$ minus bias term $b$ was too **big**!\n",
    "\n",
    "We have a clear optimization signal here, we have to either increase or decrease the size of the value before we take its *sign*, we have two possible solutions:\n",
    "\n",
    "1. The easiest is that we can simply increase/decrease the size of the bias to limit the effect of the dot product, in which ever way prevents the problem (too big vs too small)\n",
    "2. Harder, is that we can look at the individual multiplications in the dot product and figure out which values in the $W$ column are contributing to this mess.\n",
    "\n",
    "We call this process \"blame attribution\", where we figure out exactly which values we can blame for mispredictions. We cover the process of blame attribution for both the false positive and false negative case:\n",
    "\n",
    "- False Positive:\n",
    "\n",
    "Continuing our example, a false positive occurs at the $5^{\\text{th}}$ entry of the $z/\\hat{z}$ pair. This means that the dot product of $5^{\\text{th}}$ column of $W$, denoted $W_5$ and $x$ exceeds that bias term $b_5$ - we can blame $b_5$ for being too small and attribute blame for it to increase in size. We can take a closer look at the values of $W_5$ and $x$ and attribute blame to the individual weights of this dot product:\n",
    "\n",
    "```\n",
    "W_5 = -1 +1 +1 -1 +1 +1 -1 +1 -1 +1\n",
    "x   = -1 +1 -1 +1 -1 +1 -1 +1 -1 +1\n",
    "```\n",
    "\n",
    "$W_5$ can blamed for this unusual result in all of its entries except entries 3,4,5. So we attribute blame accordingly to these entries.\n",
    "\n",
    "- False Negative:\n",
    "\n",
    "In our example, the false negative occurs at the $6^{\\text{th}}$ entry of the $z/\\hat{z}$ pair. So we blame the bias term $b_6$ for being too large, and examine the dot product to $W_6$ as we did above to attribute blame:\n",
    "\n",
    "```\n",
    "W_6 = +1 -1 +1 +1 -1 +1 +1 -1 +1 -1 \n",
    "x   = -1 +1 -1 +1 -1 +1 -1 +1 -1 +1\n",
    "```\n",
    "\n",
    "And now it is entries 4, 5, 6 that can be blamed for this false negative.\n",
    "\n",
    "### Keeping Score\n",
    "\n",
    "Now that we have our basic optimization signals, we can start tallying them, much in the same way as Plumerai's BOP tallies evidence determined from backpropagation. As a reminder, each weight is expected to have an unsigned blame counter that keeps track of the blame attributed to it as the network cycles through tasks, and similarly each bias term, however - this blame counter in this case is signed.\n",
    "\n",
    "Once the blame counted, passes a certain threshold, either the weight is flipped or the bias is increment/decrement (dependent on sign). Most importantly, the process must also forgive blame by periodically incrementing/decrementing all counters towards 0 - this has the desired effect of removing erroneous blame that is attributed either as a result of noise in the data or from historical behaviour as the Perceptron is tuned.\n",
    "\n",
    "With all of this, we are now ready to implement a binarized Perceptron.\n",
    "\n",
    "### Implementation\n",
    "\n",
    "We will train the binarized perceptron on the famous `MNIST` dataset, below we are given a simple viewer which shows how individual samples of the MNIST dataset are thresholded into a binarized from that we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-12 23:20:49.540999: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-12 23:20:49.715584: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-12 23:20:50.761889: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-12 23:20:50.761961: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-12 23:20:50.761971: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-11-12 23:20:52.767095: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-11-12 23:20:52.786618: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-12 23:20:52.786634: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-12 23:20:52.787038: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Pretty MNIST rendering\n",
    "fig, axs = plt.subplots(1,2)\n",
    "\n",
    "IMAGE_TO_PREVIEW = 782\n",
    "THRESHOLD = 128\n",
    "\n",
    "original = axs[0].imshow(x_train[IMAGE_TO_PREVIEW].reshape(28,28))\n",
    "binarized = axs[1].imshow((x_train[IMAGE_TO_PREVIEW].reshape(28,28) > THRESHOLD)*2-1)\n",
    "\n",
    "plt.colorbar(original,orientation='horizontal')\n",
    "plt.colorbar(binarized,orientation='horizontal')\n",
    "\n",
    "axs[0].set_title(\"Original Image of a \"+str(y_train[IMAGE_TO_PREVIEW]))\n",
    "axs[1].set_title(\"Binarized Image of a \"+str(y_train[IMAGE_TO_PREVIEW]))\n",
    "axs[0].tick_params(axis='both',bottom=False,labelbottom=False,left=False,labelleft=False)\n",
    "axs[1].tick_params(axis='both',bottom=False,labelbottom=False,left=False,labelleft=False)\n",
    "\n",
    "# Full data conversion\n",
    "x_train = ((x_train > THRESHOLD)*2 - 1).reshape(x_train.shape[0],28*28)\n",
    "x_test = ((x_test > THRESHOLD)*2 - 1).reshape(x_test.shape[0],28*28)\n",
    "y_train = tf.one_hot(y_train,depth=10)*2 - 1\n",
    "y_test = tf.one_hot(y_test,depth=10)*2 - 1\n",
    "\n",
    "# Render pretty MNIST render\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data correctly loaded, we can begin by initializing the Perceptron itself, we will do this by\n",
    "\n",
    "- Initializing $W$ to be a random binarized matrix of size 784-by-10\n",
    "- Initializing $b$ to be a random integer matrix of size 10 with entries between 0 and 784\n",
    "- Initializing all blame counters for both $W$ and $b$ and define increment/flipping thresholds\n",
    "- Initialize counter and define time at which to decrement counter (this is usually the average expected time of two samples of the same class)\n",
    "\n",
    "In particular, we'd like to emphasize that the blame counters can be especially small - that is, only 4-8 bits are required for blame attribution, as opposed to the full floating point number required in Plumerai's Latent-Free approach. This makes our training requirements very small.\n",
    "\n",
    "Training in general is much more sensitive to the counter decay rate than anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 10), (10,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set seed for reproducability\n",
    "SEED = 1337\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# Define random W and b\n",
    "W = (np.random.uniform(0,1,(784,10)) < 0.5)*2 - 1\n",
    "b = np.random.randint(0,784,10)\n",
    "\n",
    "# Create blame attribution counters\n",
    "W_blame = np.zeros((784,10))\n",
    "b_blame = np.zeros(10)\n",
    "\n",
    "# Define the requisite thresholds\n",
    "W_THRES = 16\n",
    "b_THRES = 4\n",
    "\n",
    "# Counters and counter logic\n",
    "counter = 0\n",
    "counter_RESET = 10\n",
    "\n",
    "W.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can finally define some functions to provide a method to process data-samples and train the perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feedforward one sample\n",
    "def forward(W,b,x):\n",
    "    out = np.sign(x@W-b)\n",
    "    out[out == 0] = 1\n",
    "    return out\n",
    "\n",
    "# Discover which columns/bias terms are to blame\n",
    "def blame_columns(z,zhat):\n",
    "\n",
    "    # Binarize inputs\n",
    "    z = z > 0\n",
    "    zhat = zhat > 0\n",
    "\n",
    "    # Compute where there are false positives and false negatives\n",
    "    false_pos = np.logical_and(zhat,np.logical_not(z))\n",
    "    false_neg = np.logical_and(np.logical_not(zhat),z)\n",
    "\n",
    "    # Increment bias blame for false positives (too big!)\n",
    "    for idx, i in enumerate(false_pos):\n",
    "        if i:\n",
    "            b_blame[idx] += 1\n",
    "\n",
    "    # Decrement bias blame for false negatives (too small!)\n",
    "    for idx, i in enumerate(false_neg):\n",
    "        if i:\n",
    "            b_blame[idx] -= 1\n",
    "\n",
    "    # If bias threshold is crossed, reset blame and increment/decrement bias\n",
    "    for idx, i in enumerate(np.abs(b_blame)>b_THRES):\n",
    "        if np.sign(b_blame[idx]) > 0 and i:\n",
    "            b[idx] += 1\n",
    "        elif np.sign(b_blame[idx]) < 0 and i:\n",
    "            b[idx] -= 1\n",
    "\n",
    "    return false_pos, false_neg\n",
    "\n",
    "def blame_weights(x,false_pos,false_neg):\n",
    "\n",
    "    # Binarize inputs\n",
    "    x = x > 0\n",
    "\n",
    "    # If a weight is found to be blame for a false positive attribute blame\n",
    "    for idx, i in enumerate(false_pos):\n",
    "        if i:\n",
    "            for jdx, j in enumerate(np.logical_not(np.logical_xor(W[:,idx]>0,x))):\n",
    "                if j:\n",
    "                    W_blame[jdx,idx] += 1\n",
    "\n",
    "    # If a weight is found to be blame for a false negative attribute blame\n",
    "    for idx, i in enumerate(false_neg):\n",
    "        if i:\n",
    "            for jdx, j in enumerate(np.logical_xor(W[:,idx]>0,x)):\n",
    "                if j:\n",
    "                    W_blame[jdx,idx] += 1\n",
    "\n",
    "    # Find where weights exceed the blame threshold\n",
    "    rows,cols = np.where(W_blame >= W_THRES)\n",
    "\n",
    "    # Reset blame counter and flip corresponding weight\n",
    "    for i,j in zip(rows,cols):\n",
    "        W_blame[i,j] = 0\n",
    "        W[i,j] = W[i,j] * -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all functions defined, we are now able to run our perceptron and train it using discrete optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 10337/60000 [00:06<00:27, 1780.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Accuracy: 0.6853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 20309/60000 [00:11<00:21, 1809.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Accuracy: 0.6847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 30318/60000 [00:17<00:16, 1806.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Accuracy: 0.6973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 40274/60000 [00:23<00:11, 1723.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Accuracy: 0.6843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 50264/60000 [00:29<00:05, 1636.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Accuracy: 0.6935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 52021/60000 [00:30<00:04, 1688.18it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tqdm(indices):\n\u001b[1;32m     15\u001b[0m     x \u001b[39m=\u001b[39m x_train[i]\n\u001b[0;32m---> 16\u001b[0m     y \u001b[39m=\u001b[39m y_train[i]\n\u001b[1;32m     18\u001b[0m     \u001b[39m# Predict\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     zhat \u001b[39m=\u001b[39m forward(W,b,x)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1072\u001b[0m, in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1066\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mname_scope(\n\u001b[1;32m   1067\u001b[0m     \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1068\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mstrided_slice\u001b[39m\u001b[39m\"\u001b[39m, [tensor] \u001b[39m+\u001b[39m begin \u001b[39m+\u001b[39m end \u001b[39m+\u001b[39m strides,\n\u001b[1;32m   1069\u001b[0m     skip_on_eager\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mas\u001b[39;00m name:\n\u001b[1;32m   1070\u001b[0m   \u001b[39mif\u001b[39;00m begin:\n\u001b[1;32m   1071\u001b[0m     packed_begin, packed_end, packed_strides \u001b[39m=\u001b[39m (stack(begin), stack(end),\n\u001b[0;32m-> 1072\u001b[0m                                                 stack(strides))\n\u001b[1;32m   1073\u001b[0m     \u001b[39m# TODO(mdan): Instead of implicitly casting, it's better to enforce the\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m     \u001b[39m# same dtypes.\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m     \u001b[39mif\u001b[39;00m (packed_begin\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mint64 \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m         packed_end\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mint64 \u001b[39mor\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m         packed_strides\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mint64):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/dispatch.py:1176\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1175\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1176\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1177\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1178\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1179\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/ops/array_ops.py:1468\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(values, axis, name)\u001b[0m\n\u001b[1;32m   1465\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1466\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1467\u001b[0m     \u001b[39m# If the input is a constant list, it can be converted to a constant op\u001b[39;00m\n\u001b[0;32m-> 1468\u001b[0m     \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(values, name\u001b[39m=\u001b[39;49mname)\n\u001b[1;32m   1469\u001b[0m   \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[1;32m   1470\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Input list contains non-constant tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1638\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1629\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1630\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1631\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1634\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1635\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m   1637\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1638\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   1640\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1641\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:343\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    341\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    342\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[0;32m--> 343\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    281\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m    282\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:304\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    303\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    305\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    306\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "acc = 0\n",
    "acc_count = 0\n",
    "REPORT = 10000\n",
    "epochs = 1\n",
    "\n",
    "for e in range(epochs):\n",
    "    print(\"EPOCH \"+str(e+1))\n",
    "    indices = np.arange(x_train.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    for i in tqdm(indices):\n",
    "\n",
    "        x = x_train[i]\n",
    "        y = y_train[i]\n",
    "\n",
    "        # Predict\n",
    "        zhat = forward(W,b,x)\n",
    "\n",
    "        # Attribute blame\n",
    "        fp,fn = blame_columns(y,zhat)\n",
    "        blame_weights(x,fp,fn)\n",
    "\n",
    "        # \"Forgiveness counter\"\n",
    "        counter += 1\n",
    "        if counter >= counter_RESET:\n",
    "            W_blame -= 1\n",
    "            W_blame[W_blame < 0] = 0\n",
    "            b_blame = np.sign(b_blame)*(np.abs(b_blame) - 1)\n",
    "            counter = 0\n",
    "\n",
    "        # Accuracy metric counter\n",
    "        acc += np.sum(np.logical_and(zhat > 0, y > 0))\n",
    "        acc_count += 1\n",
    "        if acc_count >= REPORT:\n",
    "            print(\"Current Accuracy: \" + str(acc / REPORT))\n",
    "            acc_count = 0\n",
    "            acc = 0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, so our model guesses labels correctly in 84% of cases, not bad for a silly counting system. As a great sanity test for perceptrons, we can see that the statistical forms of our various characters have embedded themselves into their corresponding layers - providing a clear insight into how the perceptron is operating:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,5)\n",
    "\n",
    "for i in range(10):\n",
    "    axs[i//5,i%5].set_title(\"Column \"+str(i))\n",
    "    axs[i//5,i%5].imshow(W[:,i].reshape(28,28))\n",
    "    axs[i//5,i%5].tick_params(axis='both',bottom=False,labelbottom=False,left=False,labelleft=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we shall test our trained network on the MNIST testing set to see how well our perceptron generalizes given lessons learnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [00:03, 2718.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Accuracy: 0.6959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "acc = 0\n",
    "acc_count = 0\n",
    "REPORT = 10000\n",
    "\n",
    "for x,y in tqdm(zip(x_test,y_test)):\n",
    "\n",
    "    #Forward\n",
    "    zhat = forward(W,b,x)\n",
    "\n",
    "    # Accuracy metric counter\n",
    "    acc += np.sum(np.logical_and(zhat > 0, y > 0))\n",
    "    acc_count += 1\n",
    "    if acc_count >= REPORT:\n",
    "        print(\"Current Accuracy: \" + str(acc / REPORT))\n",
    "        acc_count = 0\n",
    "        acc = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
